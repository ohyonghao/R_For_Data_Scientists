---
title: "Homework 3"
author: "DTR"
date: 'Due: Tuesday 5/12/2020 by 4:30 pm'
output: rmdformats::material
subtitle: 'STAT 399'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(magrittr)
library(dplyr)
library(readr)
library(tidyr)
library(pander)
```


# Part 0: Getting to know the data

We are grabbing three sets of data to analyze the current Coronavirus situation in the US. We have a time series data, daily reports, and some 
general statistics about each state.

```{r load_data, echo=FALSE, message=FALSE}
covid.usa.ts <- read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')

covid.usa.daily <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/05-07-2020.csv") 

popdata <- read_csv("https://www2.census.gov/programs-surveys/popest/tables/2010-2018/state/asrh/sc-est2018-alldata5.csv")
```


```{r}
names(covid.usa.ts)
```

This quick look tells us that the first 11 columns are information, and the last 123 columns are
the time series data.

```{r}
head(covid.usa.daily)
```

We see this information is an aggregate of information between April 14th and May 7th as offered
in the description.


# Part 1: Wrangling the COVID-19 data

Now that we've gotten to see the data a little bit we can now try to wrangle it into a form that we can make some sense out of.
```{r}
library(parallel)
```

To get the primary keys we'll write a quick function to test. If all values are unique then it is
a key.

```{r Primary Keys}
primary_keys <- function( data, keysonly = FALSE ){
        if( keysonly ){
                keys <-primary_keys(data)
                return(keys[keys==TRUE])
        }else{
        mclapply(data, function(x){
                return( length(unique(x)) == length(x))
                })
        }
}
```


Covid USA Time Series"
```{r}
str(primary_keys(covid.usa.ts[,c(1:11)], keysonly=TRUE))
```

The keys for `covid.usa.ts` are the `UID`, and `Combined_Key`. These two each functionaly
determine the rest of the elements.

Covid USA Daily
```{r}
str(primary_keys(covid.usa.daily, keysonly=TRUE))
```

For the `covid.usa.daily` dataset we find `Province_State`, `Confirmed`, `FIPS`, `Mortality_Rate`,
and `UID` are keys.


```{r}
tmp <- left_join( covid.usa.ts[,1:11], rename( covid.usa.daily, ), by= c( "UID" = "UID" ) )
tmp %>% filter(Province_State.x == Province_State.y) %>%
        select( Province_State.x, Province_State.y )
```

The foreign keys between these two tables is the `Province_State` which is in `covid.usa.ts` 
with the foreign key being in `covid.usa.daily`. The `UID` column does not appear to be a
foreign key.

## Aggregating State Level Data

```{r State Level Time Series}
covid.usa.states.ts <- covid.usa.ts %>%
        group_by(Province_State) %>%
        summarize_at( vars(-names(.)[1:6],-names(.)[8:11]) ,sum,na.rm=TRUE )
covid.usa.states.ts
```

## Combining Data

We'll use the foreign key `Province_State` to do a left join on these
tables.

```{r}
covid.usa.all <- left_join(covid.usa.daily, covid.usa.states.ts,  by="Province_State")
```



# Part 2: Wrangling the population data

We'd like to bucket the age groups

```{r}
names(popdata)
unique(popdata$AGE)
```

Trust, but verify, take a random sample and see that the function worked as
expected.
```{r}
pop.data <- popdata %>%
        mutate(AGE.GRP = case_when(
                (AGE >= 0  & AGE < 6)  ~ "0-5", 
                (AGE >= 6  & AGE < 19) ~ "6-18",
                (AGE >= 19 & AGE < 41) ~ "19-40", 
                (AGE >= 41 & AGE < 71) ~ "41-70",
                (AGE >= 71)            ~ "71+" 
                ) 
              )

sample_n(pop.data, 50) %>%
        select(AGE,AGE.GRP)
```

Now to aggregate the population for 2018.

```{r}
pop.agg <- pop.data %>%
        group_by(NAME, AGE.GRP, SEX) %>%
        select(SUMLEV:AGE,POPESTIMATE2018, AGE.GRP) %>%
        summarize_at( vars(POPESTIMATE2018), sum, na.rm=TRUE) %>%
        ungroup()
head(pop.agg, 5)
```

# Part 3: Let's combine and use the data

### The most impacted states

We'll first reshape our data:

```{r}
covid.usa.rs <- covid.usa.all %>%
        pivot_longer(`1/22/20`:`5/13/20`, 
                     names_to = "Date", 
                     values_to = "Cases",
                     values_drop_na = TRUE) %>%
        mutate(Date = as.POSIXct(strptime(Date, format="%m/%d/%y")))
covid.usa.rs
```


```{r top_bott_n}
# Inputs:
# x: a dataframe
# n: number of units top and bottom, total number is 2n
# wt: Column to base ranking on
top_bott_n <- function( x, n, wt ){
        wt <- enquo(wt)
        x %>%
        filter(!between(dense_rank(!!wt), n+1, n() - n))
}
```


```{r}
covid.usa.impacted <- 
        covid.usa.rs %>%
                group_by(Province_State) %>%
                summarize( Cases = sum(Cases,na.rm=TRUE) ) %>%
                arrange( desc(Cases) ) %>%
                filter(Cases > 6300) %>%
                top_bott_n( 3, Cases)
covid.usa.impacted.top <- covid.usa.impacted %>%
        top_n(3, Cases)
covid.usa.impacted.bottom <- covid.usa.impacted %>%
        top_n(3,-Cases)
covid.usa.impacted.agegrp <-
        covid.usa.rs %>%
                group_by(Province_State,) %>%
                summarize( Cases = sum(Cases,na.rm=TRUE) ) %>%
                arrange( desc(Cases) ) %>%
                filter(Cases > 6300) %>%
                top_bott_n( 3, Cases)
covid.usa.impacted
```

We see the 6 states listed above have the most and least number of cases.

### Visualizing Impact

```{r}
library(cowplot)
p <- covid.usa.rs %>%
        filter( Province_State %in% covid.usa.impacted.top$Province_State & 
                        Date >= strptime("3/15/20","%m/%d/%y") ) %>%
        ggplot( mapping=aes(x=`Date`, y=`Cases`, group=Province_State, color=Province_State)) +
        geom_line() +
        facet_wrap(~Province_State) +
        labs( title = "Most Impacted States") + 
        theme(axis.text.x = element_text(angle = 45, hjust=1))
p2 <- covid.usa.rs %>%
        filter( Province_State %in% covid.usa.impacted.bottom$Province_State & 
                        Date >= strptime("3/15/20","%m/%d/%y") ) %>%
        ggplot( mapping=aes(x=`Date`, y=`Cases`, group=Province_State, color=Province_State)) +
        geom_line() + 
        facet_wrap(~Province_State) +
        labs( title = "Least Impacted States") + 
        theme(axis.text.x = element_text(angle = 45, hjust=1))
cowplot::plot_grid(p,p2, nrow = 2, rel_heights=c(0.5,0.5)) + labs(title = "Covid19 Impact")
```

### Does Stay at Home Help?

As is often the case this resembles a logrithmic curve that we are starting to plateu on.
For the three most impacted states there isn't a descernable difference pre or post stay
at home order. They all were about the same time, March 24th, 21st, and 22nd respectively. Their
inflection point are all around April 7th.

Looking at the least impacted states, on the other hand, we see Alaska and Montana having
their inflection point earlier around April 1st, even though they both waited until March
28th for their stay at home orders. Noticibly missing from the list of stay at home orders
is Wyoming, and it is noticble that they are experiencing linear growth rather than logrithmic.

### Age, Gender, and Race Impact

```{r Age Gender Race}
agr.agg <- pop.agg %>%
        group_by(NAME) %>%
        summarize(Population =sum(POPESTIMATE2018,na.rm=TRUE) ) %>%
        select(NAME,Population)

agr.daily <- covid.usa.daily %>%
        filter(Province_State %in% pop.agg$NAME) %>%
        mutate( StatePopulation= agr.agg$Population)

agr.join <- left_join(pop.agg, agr.daily, by=c("NAME"="Province_State")) %>%
        mutate( Confirmed.Age = Confirmed * (POPESTIMATE2018/StatePopulation))
agr.join$AGE.GRP = as.factor(agr.join$AGE.GRP)
```

Next we'll take the population makeup and assume the cases have been distributed evenly
throughout each and see if states with a certain group have higher rates.

```{r}
#str(agr.join)
agr.join
```

```{r}
agr.p <- agr.join %>% 
        ggplot(mapping=aes(y=Confirmed.Age,x=AGE.GRP, group=AGE.GRP)) +
        geom_col() +
        labs(x="Age Group", y="Estimated Case by Age", title="Distribution Across Age Groups")
agr.p


###
